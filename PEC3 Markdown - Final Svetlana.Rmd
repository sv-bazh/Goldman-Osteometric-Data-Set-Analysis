---
title: "PEC 3 - Svetlana Bazhenova y Pablo Castejon Molina"
output:
  pdf_document: default
  html_document: default
date: '2022-06-11'
---

# Apartado 1


El set de datos elegido para este trabajo es el "Goldman Osteometric Data Set". Este dataset incluye datos relativos a 1538 esqueletos humanos de distintas epocas del Holoceno. Los datos recogidos comprenden variables lineales de 4 huesos largos de las piernas (humero, radio, femur y tibia) y tres variables extra de la pelvis. De manera adicional, se estimo el sexo a partir de la morfologia pelvica y dicha estimacion se incluyo en el Data Set.

El Data Set puede descargarse desde la siguiente pagina: https://web.utk.edu/~auerbach/GOLD.htm#gold

Referencias:

 - Auerbach BM, & Ruff CB. 2004. Human body mass estimation: a comparison of “morphometric” and “mechanical” methods. American Journal of Physical Anthropology 125:331-342.

 - Auerbach BM, & Ruff CB. 2006. Limb bone bilateral asymmetry: variability and commonality among modern humans. Journal of Human Evolution 50:203-218.

 - Temple DH, Auerbach BM, Nakatsukasa M, & Larsen CS. 2008. Variation in body proportions between Jomon foragers and Yayoi agriculturalists from prehistoric Japan. American Journal of Physical Anthropology 137:164-174.

 - Betti L, Von Cramon-Taubadel N, Lycett SJ. 2012. Human pelvis and long bones reveal differential preservation of ancient population history and migration out of Africa. Human Biology 84:139-152.

 - Plavcan JM. 2012. Body size, size variation, and sexual size dimorphism in Early Homo. Current Anthropology 53:S409-S423.

 - Stock JT. 2013. The skeletal phenotype of "Negritos" from the Andaman Islands and Philippines relative to global variation among hunter-gatherers. Human Biology 85:67-94.

 - Roseman CC & Auerbach BM. 2015. Ecogeography, genetics, and the evolution of human body form. Journal of Human Evolution 78:80-90.

 - Savell KRR, Auerbach BM, & Roseman CC. 2016. Constraint, natural selection, and the evolution of human body form. Proceedings of the National Academy of Sciences USA 113:9492-9497.


Hemos seleccionado estos datos por el interés científico que consideramos que tienen, además de por su gran valor desde el punto de vista de la Bioestádistica: Esta formado por una muestra poblacional muy extensa, incluye múltiples variables de distinto tipo y puede permitirnos inferir mucha información que antes era desconocida a través de un acercamiento y estudio apropiado.



# Apartado 2


El archivo se ha descargado de la dirección citada anteriormente, en formato csv, y se nombra como "data".

```{r}
download.file("https://web.utk.edu/~auerbach/Goldman.csv", destfile = "data")
```
Se carga el archivo en R y se muestran las primeras lineas:

```{r}
data1 <- read.csv("data")
head(data1)
```

Tras ello, se muestra un resumen de las variables y su tipo:

```{r}
summary(data1)
str(data1)

```
Como puede verse, el dataset tiene una gran cantidad de variables de distintos tipos (1538 observaciones de  69 variables), incluyendo numéricas (las relativas a las mediciones en los huesos), cualitativas (las relativas a la presencia o ausencia de uno de los huesos) y de caracteres (información adicional como el sexo, el código de identificación o el lugar del yacimiento).


La descripcion de las medidas se encuentra en el PDF encontrado en el mismo sitio que los datos: https://web.utk.edu/~auerbach/GoldMeasures.pdf 

Podemos ver que las columnas Elements, Metrics y Derived estan compuestas unicamente de NA y sirven unicamente a separar las variables por tipo establecido por los autores (Elements, Metrics y Derived) dentro del dataset.

Otras cosas importantes de notar:

- las variables de tipo Elements (LHUM, RHUM, LRAD, RRAD, LFEM, RFEM, LTIB, RTIB, OSCX) son de tipo categorico (0 y 1) y tienen un significado contraintuitivo (0 significa que el elemento es presente y almenos una medida ha sido prelevada y 1 que es ausente)
- Las variables de tipo Metrics descritas en el PDF son presentes dos veces: una para la izquierda, el nombre de la variable empezando con la letra L (left), una para la derecha, empezando con R (right), por ejemplo en vez de tener senciallamente IBL (descripcion: Maximum Iliac Blade Length), en el dataset tenemos a RIBL y LIBL

# Apartado 3

Preguntas posibles:

a) ¿Que huesos se preservan mas de la derecha si se preserva la izquierda? (Elements)
b) ¿Los museos estan especializados en origen de huesos? 
c) (Metrics) la variable BIB (Bi‐iliac Breadth) no tiene derecha ni izquierda. Hay alguna variable con cuya ella esta correlada (que no sea genero)
d) Variable Sex : podemos hacer una predicion de genero a partir de este dataset para las observaciones donde Sex esta marcado como 0? y 1? ? Los resultados coinciden con el metodo que usaron los autores?
e) ¿Tienen de media los húmeros derechos e izquierdos (LHML y RHML) la misma longitud máxima  o hay diferencias?
f) ¿Que porcentaje de la población total corresponde a los individuos de +50 años? ¿En qué llacimiento hay mas individuos de este rango de población?

Respuetas:

#### a) ¿Que huesos se preservan mas de la derecha si se preserva la izquierda? (Elements)

Tenemos que mirar la proporcion de preservacion de las variables de tipo Elements (LHUM, RHUM, LRAD, RRAD, LFEM, RFEM, LTIB, RTIB). La poblacion completa para medir el porcentaje de preservacion de los huesos derechas seria para cada par (LHUM y RHUM, LRAD y RRAD, LFEM y RFEM, LTIB y RTIB) la poblacion donde la preservacion de huesos izquierdos seria completa (== 0)


```{r}
#Se prepara un nuevo data set, donde esta preservado el LHUM
LHUM_preservado <- data1[data1$LHUM == '0', ]
LHUM_preservado <- LHUM_preservado[!is.na(LHUM_preservado$LHUM),]

# Y aqui preparamos el subdataset de LHUM que solo tiene los RHUM preservados
RHUM_preservado <- LHUM_preservado[LHUM_preservado$RHUM == '0', ]
RHUM_preservado <- RHUM_preservado[!is.na(RHUM_preservado$RHUM),]

# proporcion de RHUM preservados cuando LHUM esta preservado
print("humerus: ")
nrow(RHUM_preservado)/nrow(LHUM_preservado)



#Se prepara un nuevo data set, donde esta preservado el LRAD
LRAD_preservado <- data1[data1$LRAD == '0', ]
LRAD_preservado <- LRAD_preservado[!is.na(LRAD_preservado$LRAD),]

# Y aqui preparamos el subdataset de LRAD que solo tiene los RRAD preservados
RRAD_preservado <- LRAD_preservado[LRAD_preservado$RRAD == '0', ]
RRAD_preservado <- RRAD_preservado[!is.na(RRAD_preservado$RRAD),]

# proporcion de RRAD preservados cuando LRAD esta preservado
print("radius: ")
nrow(RRAD_preservado)/nrow(LRAD_preservado)



#Se prepara un nuevo data set, donde esta preservado el LFEM
LFEM_preservado <- data1[data1$LFEM == '0', ]
LFEM_preservado <- LFEM_preservado[!is.na(LFEM_preservado$LFEM),]

# Y aqui preparamos el subdataset de LFEM que solo tiene los RFEM preservados
RFEM_preservado <- LFEM_preservado[LFEM_preservado$RFEM == '0', ]
RFEM_preservado <- RFEM_preservado[!is.na(RFEM_preservado$RFEM),]

# proporcion de RFEM preservados cuando LFEM esta preservado
print("femur: ")
nrow(RFEM_preservado)/nrow(LFEM_preservado)



#Se prepara un nuevo data set, donde esta preservado el LTIB
LTIB_preservado <- data1[data1$LTIB == '0', ]
LTIB_preservado <- LTIB_preservado[!is.na(LTIB_preservado$LTIB),]

# Y aqui preparamos el subdataset de LTIB que solo tiene los RTIB preservados
RTIB_preservado <- LTIB_preservado[LTIB_preservado$RTIB == '0', ]
RTIB_preservado <- RTIB_preservado[!is.na(RTIB_preservado$RTIB),]

# proporcion de RTIB preservados cuando LTIB esta preservado
print("tibia: ")
nrow(RTIB_preservado)/nrow(LTIB_preservado)
```

Vemos que la proporcion mas alta la tienen LFEM y RFEM que son los femures. No deberia ser una sorpresa ya que es el hueso mas largo y fuerte del cuerpo humano asi que lo logico seria que es el que se preserve mas, también proporcialmente entre la derecha y la izquierda.

#### b) ¿Los museos estan especializados en origen de huesos? 

Podemos hacer unos barplots por museo

```{r}
par(mar=c(5,10,4,4))
barplot(table(data1$Location,data1$Inst),horiz=TRUE,las=2, cex.names=.6,col = rainbow(length(unique(data1$Location))))

```
El barplot sale muy colorado. Podemos ver que WOAC, SfAP, KU, KSU y CMNH estan muy especializados cada uno en una Location (la barra es mayoritarmente de un unico color). Cual?
Para averiguarlo, podemos hacer un subset del dataset componiendolo unicamente de observaciones de estos museos.

```{r}
inst_woac <- data1[data1$Inst == 'WOAC', ]
inst_sfap <- data1[data1$Inst == 'SfAP', ]
inst_ku <- data1[data1$Inst == 'KU', ]
inst_ksu <- data1[data1$Inst == 'KSU', ]
inst_cmnh <- data1[data1$Inst == 'CMNH', ]

# mostramos la reparticion de los origenes por museo
table(inst_woac$Location,inst_woac$Inst)
table(inst_sfap$Location,inst_sfap$Inst)
table(inst_ku$Location,inst_ku$Inst)
table(inst_ksu$Location,inst_ksu$Inst)
table(inst_cmnh$Location,inst_cmnh$Inst)

```
Vemos que los museos "especializados" en un origen de los huesos tienden a tener colleciones regionales de la region o pais donde esta el museo. Asi mismo, WOAC – Webb Osteology and Archaeology Collection (que se encuentra en el estado de Kentucky, EEUU) tiene unicamente los huesos con origen en Kentucky. SfAP – Staatssammlung fur Anthropologie und Palaeoanatomie (que es una collecion alemana) los huesos con origen en Alemania (a l'exepcion de un ejemplar de Tanzania), KU – Kyoto University (Kyodai) con origen en Japon, KSU – Kent State University y CMNH – Cleveland Museum of Natural History los huesos con origen de Ohio (que es el estado donde estan).


#### c) (Metrics) la variable BIB (Bi‐iliac Breadth) no tiene derecha ni izquierda. Hay alguna variable con cuya ella esta correlada (que no sea genero)

```{r}
#Se importa zoo para realizar la sustitución rápidamente
#install.packages("zoo")

# ponemos las metricas en un dataset a parte
metrics <- data1[,c(18:60)]

library(zoo)
# reemplazamos los NA en cada variable con la media de la variable
metrics2 <- na.aggregate(metrics)

# miramos la correlacion de cada variable con BIB
cor(metrics2[-39], metrics2$BIB)
```

La correlacion mas grande de BIB es con RIBL (Right Maximum Iliac Blade Length) (0.6679058) y LIBL (Left Maximum Iliac Blade Length) (0.6501100).


#### d) Variable Sex : podemos hacer una predicion de genero a partir de este dataset para las observaciones donde Sex esta marcado como 0? y 1? ? Los resultados coinciden con el metodo que usaron los autores?

Podemos usar un algoritmo de clasificacion, por ejempo Support Vector Machine (SVM)

Para aplicar ese algoritmo, hemos seguido en parte las instrucciones encontradas aqui: https://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-r/ 

```{r}
# separamos el dataset data2 en grupos test y train. El test va a incluir todas las observaciones donde el genero no esta seguro (marcado 0? o 1?) y el train todas las demas observaciones.

data2_test <- data1[data1$Sex == '0?'| data1$Sex == '1?', ]
data2_train <- data1[data1$Sex == '0'| data1$Sex == '1', ]

# en el dataset test reemplazamos los valores 0? y 1? con un el equivalente 0 y 1 para compararlos después de entrenar el algoritmo
data2_test$Sex<-replace(data2_test$Sex, data2_test$Sex=="0?","0") 
data2_test$Sex<-replace(data2_test$Sex, data2_test$Sex=="1?","1") 

# para el dataset final de train y test, necesitamos unicamente las columnas de metricas
metricsgen_train <- data2_train[,c(18:60)]
metricsgen_test <- data2_test[,c(18:60)]

# para la variable que va a ser predecida, tomamos a parte la columna Sex en ambos dataset train y test
sex_train <- data2_train[,c(3)]
sex_test <- data2_test[,c(3)]

# pasamos a tipo factor la variable predecida en ambos train y test
sex_train<-factor(sex_train, levels = c(0, 1))
sex_test<-factor(sex_test, levels = c(0, 1))

# reemplazamos con la media de la variable las observaciones que tienen NA en ambos train y test
library(zoo)
metricsgen_train <- na.aggregate(metricsgen_train)
metricsgen_test <- na.aggregate(metricsgen_test)

head(metricsgen_test)
head(metricsgen_train)
sex_test
```
```{r}
# Feature Scaling: necesitamos escalar las variables en train y test para que esten entre -1 y 1
metricsgen_train = scale(metricsgen_train)
metricsgen_test = scale(metricsgen_test)


# Aplicamos el algoritmo SVM al dataset de train con la variable de prediccion sex_train
#install.packages('e1071')
library(e1071)
 
classifier = svm(formula = sex_train ~ .,
                 data = metricsgen_train,
                 type = 'C-classification',
                 kernel = 'linear')

# predecimos los resultados de test con el classifier creado
y_pred = predict(classifier, newdata = metricsgen_test)

# creamos la matriz de confusion para ver si ha funcionado
cm = table(sex_test, y_pred)
cm
```

Leyendo a la matriz de confusion, tenemos a 4 verdaderos positivos, 1 falso positivo, 2 falsos negativos y 3 verdaderos negativos.  La accuracy es entonces de 7/10 o sea que en 7 casos de los 10, los resultados creados con SVM son los mismos que los que los autores han usado para predecir el genero de las observaciones donde el genero faltaba. Ahora el problema es que no sabiendo si las observaciones marcadas con ? en la columna Sex apartienen de verdad al genero asignado, es dificil saber si nuestro algoritmo a sido eficiente.

# Apartado 4

El data set que tenemos contiene muchas variables que podemos cruzar en varios modos para hacernos unas preguntas. 

### - Unificacion de los formatos de la variable $Age:

Los catagorias de edad no tienen la misma composicion (20‐22; 22‐25; 25‐30; 30‐40; 40‐50; 50+) o sea que entre 20 y 30 anos tenemos a 3 categorias diferentes (20‐22; 22‐25; 25‐30) y todas las edades superiores a 50 estan en una categoria (50+). Mirando las observaciones por categoria, vemos que hay aun mas dispersion de edades:

```{r}
library(ggplot2)    

barplot(sort(table(data1$Age),decreasing = FALSE),horiz=TRUE, las=2, cex.names=.6)

```
Si si usa la variable Age, nos conviene unificar los valores de las observaciones, estableciendo unas categorias fijas, por ejempo <25 (dado que hay alcunas observaciones que estan en la categoria empezando con 18), 25-30, 30-40, 40-50, 50+

```{r}
data2<-data1
data2$Age<-replace(data2$Age, data2$Age<25,"18-25") 
data2$Age<-replace(data2$Age, data2$Age>=50,"50+") 
data2$Age<-replace(data2$Age, data2$Age>=25 & data2$Age<30,"25-30") 
data2$Age<-replace(data2$Age, data2$Age>=30 & data2$Age<40,"30-40") 
data2$Age<-replace(data2$Age, data2$Age>=40 & data2$Age<50,"40-50") 


#miramos la distribucion de las nuevas categorias de edades ahora
sort(table(data2$Age),decreasing = TRUE)
barplot(table(data2$Age), las=2, cex.names=.6)

```
Tenemos ahora a una distribucion similar a la normal con la mayoria de las observaciones aparteniendo a individuos entre 30 y 50 anos.

### - Investigacion de la variable Location

Seria interesante también ver la distribucion de los orígenes de las observaciones (para un usuario no familiarizado con los sitios arqueologicos, en vez de usar la variable Nota que tiene el nombre del sitio arqueologico de origen, usaremos la variable Location)

```{r}
sort(table(data2$Location),decreasing = TRUE)

par(mar=c(4,10,4,4))
barplot(sort(table(data2$Location),decreasing = FALSE),horiz=TRUE, las=2, cex.names=.6)
length(unique(data2$Location))
```
Vemos que la mayoria de las observaciones tienen origen en EEUU, seguidos por Egipto y Italia.

### - Investigacion de la variable $Inst

Finalmente, nos gustaria ver un poco la distribucion de las observaciones por museo (variable Inst)

```{r}
sort(table(data2$Inst),decreasing = TRUE)

par(mar=c(4,10,4,4))
barplot(sort(table(data2$Inst),decreasing = FALSE),horiz=TRUE, las=2, cex.names=.6)

```
Los museos donde se encuentran mas huesos observados son NMNH (Smithsonian National Museum of Natural History), AMNH (American Museum of Natural History), CMNH (Cleveland Museum of Natural History), MdH (Musee de l’Homme) y NM (Naturhistorisches Museum)

### - Variable $Sex

```{r}
sort(table(data2$Sex),decreasing = TRUE)

par(mar=c(4,10,4,4))
barplot(sort(table(data2$Sex),decreasing = FALSE),horiz=TRUE, las=2, cex.names=.6)

# porcentaje de observaciones donde no estan seguros del genero
10/1538
```
Vemos que tenemos casi el doble de observaciones provenientes de individuos hombres que de las mujeres. El numero de observaciones donde los autores no estan seguros del genero es inferior a 1% (es de 0.65%). Hemos intentado en apartado 3 determinar el genero con un algoritmo de clasificacion SVM pero no llegamos a los mismos resultados que los autores (teniamos 30% de error) 

### - Frecuencias de las variables de tipo Elements (LHUM, RHUM, LRAD, RRAD, LFEM, RFEM, LTIB, RTIB, OSCX)

```{r}

table(data2$LHUM)
table(data2$RHUM)
table(data2$LRAD)
table(data2$RRAD)
table(data2$LFEM)
table(data2$RFEM)
table(data2$LTIB)
table(data2$RTIB)
table(data2$OSCX)


par(mfrow=c(4,2))

barplot(table(data2$LHUM),horiz=TRUE,xlab="LHUM")
barplot(table(data2$RHUM),horiz=TRUE,xlab="RHUM")
barplot(table(data2$LRAD),horiz=TRUE,xlab="LRAD")
barplot(table(data2$RRAD),horiz=TRUE,xlab="RRAD")
barplot(table(data2$LFEM),horiz=TRUE,xlab="LFEM")
barplot(table(data2$RFEM),horiz=TRUE,xlab="RFEM")
barplot(table(data2$LTIB),horiz=TRUE,xlab="LTIB")
barplot(table(data2$RTIB),horiz=TRUE,xlab="RTIB")
barplot(table(data2$OSCX),horiz=TRUE,xlab="OSCX")


```

Podemos ver que en todas las variables predomina la presencia del elemento y no su ausencia. 

En cuanto a las variables del tipo Metrics, podemos ver su distribucion con unos Boxplot. Lo intuitivo puede ser mirar al lado las variables los huesos de izquierda y su equivalente de derecha

```{r}
# ponemos las metricas en un dataset a parte
metrics <- data2[,c(18:60)]
# reordenamos la metrica para tener la izquierda al lado de la derecha para cada variable
metrics <- metrics[, c(1,6,2,7,3,8,4,9,5,10,11,14,12,15,13,16,17,24,18,25,19,26,20,27,21,28,22,29,23,30,31,35,32,36,33,37,34,38,40,41,42,43,39)]


boxplot(metrics,las=2, cex.names=.2)
```

Podemos ver ya que hay siempre una cierta disproporcion entre las variables de la izquierda y de la derecha, que sea de tamano promedio o de la varianza. 


# Apartado 5

Este data set permite múltiples cálculos probabilísticos, dada la gran cantidad de variables y distribuciones que contiene. 

### Si se selecciona un individuo al azar, ¿Cual es la probabilidad de que su achura bi-ilíaca (BIB) sea mayor que 270 mm?

```{r}
#Primero se prepara un data set con los datos de la variable BIB (quitando los valores NA):
data_BIB_todaslasvariables <- data1[!is.na(data1$BIB),]
data_BIB <- data_BIB_todaslasvariables$BIB
#Se comprueba normalidad
ks.test(data_BIB, 'pnorm')
#como hay normalidad, se calcula media y desviación típica de la distribución para calcular las probabilidades.
mean(data_BIB)
sd(data_BIB)
pnorm(q=270, mean = mean(data_BIB), sd = sd(data_BIB), lower.tail = FALSE)
```
La probabilidad es del 33,87%.


### Si se selecciona una mujer al azar, ¿Cual es la probabilidad de que su achura bi-ilíaca (BIB) sea mayor que 270 mm?

```{r}
#Se prepara un nuevo data set, esta vez solo con mujeres, de la variable BIB.
BIB_mujeres <- data1[data1$Sex == '1', ]
data_BIB_variablesmujeres <- BIB_mujeres[!is.na(BIB_mujeres$BIB),]
data_BIB_mujeres <- data_BIB_variablesmujeres$BIB
#Se comprueba normalidad
ks.test(data_BIB_mujeres, 'pnorm')
#como hay normalidad, se calcula media y desviación típica de la distribución para calcular las probabilidades.
mean(data_BIB_mujeres)
sd(data_BIB_mujeres)
pnorm(q=270, mean = mean(data_BIB_mujeres), sd = sd(data_BIB_mujeres), lower.tail = FALSE)

```
La probabilidad es del 22,32%.


### Si se selecciona un hombre al azar, ¿Cual es la probabilidad de que su achura bi-ilíaca (BIB) esté comprendida entre los 260 y los 280 mm?

```{r}
#Se prepara otro data set, esta vez solo con hombres, de la variable BIB.
BIB_hombres <- data1[data1$Sex == '0', ]
data_BIB_variableshombres <- BIB_hombres[!is.na(BIB_hombres$BIB),]
data_BIB_hombres <- data_BIB_variableshombres$BIB
#Se comprueba normalidad
ks.test(data_BIB_hombres, 'pnorm')
#como hay normalidad, se usa la media y desviación típica de la distribución para calcular la probabilidad de interés. Se emplea la fórmula siguiente:
1-pnorm(q=260, mean = mean(data_BIB_hombres), sd = sd(data_BIB_hombres), lower.tail = TRUE)-pnorm(q=280, mean = mean(data_BIB_hombres), sd = sd(data_BIB_hombres), lower.tail = FALSE)
```
La probabilidad es del 41,60%.


# Apartado 6

Antes de empezar, para poder realizar las regresiones lineales, es necesario modificar el data frame para excluir los valores NA. Para ello se itera en el data set, sustituyendo cada NA por la media de su columna:

```{r}
#Se importa zoo para realizar la sustitución rápidamente
library(zoo)
metrics2 <- na.aggregate(metrics)
#Dado que el pool de variables es muy grande, el dataframe metrics2 creado anteriormente se divide en dos.
metrics2_1 <- metrics2[, c(1,6,2,7,3,8,4,9,5,10,11,14,12,15,13,16,17,24,18,25,19,26,20,27)]
metrics2_2 <- metrics2[, c(21,28,22,29,23,30,31,35,32,36,33,37,34,38,40,41,42,43,39)]

#Se observa si hay correlación entre variables.
library(corrplot)
corrplot(cor(metrics2_1), method="number",order="hclust")
corrplot(cor(metrics2_2), method="number",order="hclust")
```

Ademés de la evidente correlación entre lados izquierdo y derecho para las mismas medidas, existe en general una alta correlación entre muchos pares. Como es dificil leer el resultado en una tabla con tantas variables, se hace de nuevo una separación en tablas mas pequeñas.

```{r}
metrics2_1_1 <- metrics2_1[, c(1,2,3,4,5,6,7,8)]
metrics2_1_2 <- metrics2_1[, c(9,10,11,12,13,14,15,16)]
metrics2_1_3 <- metrics2_1[, c(17,18,19,20,21,22,23,24)]
metrics2_2 <- metrics2[, c(21,28,22,29,23,30,31,35,32,36,33,37,34,38,40,41,42,43,39)]
metrics2_2_1 <- metrics2_2[, c(1,2,3,4,5,6,7,8)]
metrics2_2_2 <- metrics2_2[, c(9,10,11,12,13,14,15,16,17,18,19)]
corrplot(cor(metrics2_1_1), method="number",order="hclust")
corrplot(cor(metrics2_1_2), method="number",order="hclust")
corrplot(cor(metrics2_1_3), method="number",order="hclust")
corrplot(cor(metrics2_2_1), method="number",order="hclust")
corrplot(cor(metrics2_2_2), method="number",order="hclust")

```
La correlacion mas alta (entre variables que no sean gemelas), se da entre los pares RHEB-RHHD, RFML-RFBL, LFML-LFBL y LFAB-RFEB.

Ahora se realizan las pruebas de regresión lineal entre estos pares:

```{r}
Regresion1<-lm(RHEB~RHHD, data=metrics2)
summary(Regresion1)
plot(RHEB~RHHD, data=metrics2)
abline(11.86, 1.08)
abline(Regresion1)

Regresion2<-lm(RFML~RFBL, data=metrics2)
summary(Regresion2)
plot(RFML~RFBL, data=metrics2)
abline(10.39, 0.94)
abline(Regresion2)

Regresion3<-lm(LFML~LFBL, data=metrics2)
summary(Regresion3)
plot(LFML~LFBL, data=metrics2)
abline(8.20, 0.99)
abline(Regresion3)

Regresion4<-lm(LFAB~RFEB, data=metrics2)
summary(Regresion4)
plot(LFAB~RFEB, data=metrics2)
abline(5.17, 0.80)
abline(Regresion4)
```

Para la regresión múltiple, hemos decidido tratar de predecir la anchura epicondilar del húmero derecho (RHEB) a partir de las otras 7 variables que también han sido usadas en la regresión simple. Se observa el modelo y también se usa el método stepwise para comprobar cuales de las variables son las mejores predictoras.


```{r}
mrm_metrics2 <- lm(metrics2$RHEB~metrics2$RHHD+metrics2$RFML+metrics2$RFBL+metrics2$LFML+metrics2$LFBL+metrics2$LFAB+metrics2$RFEB)
summary(mrm_metrics2)
step(object=mrm_metrics2,direction ="both", trace=1)
```

Según el método stepwise, las mejores variables de este conjunto para predecir RHEB son RHHD, LFBL y RFEB.

# Apartado 7

Está documentado en Antropología Física desde hace mucho tiempo el hecho de que existen diferencias significativas entre sexos para una gran cantidad de variables óseas lineales. Generalmente, el tamaño de los huesos masculinos es mayor que el de los femeninos. En el data set que hemos empleado hay multitud de ejemplos de este fenómeno, pues  suele darse abundantemente en variables de huesos largos. 

Por esta razón hemos decidido usar una variable de la cadera (formada por huesos planos en vez de largos), y asi dilucidar si el fenómeno de dimorfismo sexual ocurre también en esta region y en esta población. La variable elegida es la Anchura Bi-ilíaca (BIB).

El primer paso ha sido quitar los casos del data set que tienen los valores "0?" y "1?" para la variable Sex (es decir, los casos cuyo sexo no es seguro).


```{r}
data_ANOVA<-data1[!(data1$Sex=="0?" | data1$Sex=="1?"),]
```

Después se ha cambiado la variable Sex de tipo "caracter" a tipo "factor" (necesario para la ANOVA):


```{r}
data_ANOVA$Sex <- as.factor(data_ANOVA$Sex)
```

Ahora se puede comenzar con la prueba ANOVA. Hay que recordar que para que la anova pueda implementarse, primero hay que demostrar normalidad entre las dos poblaciones que se comparen (en este caso, hombres y mujeres), asi como igualdad de varianzas en sus distribuciones. 

### ANOVA

Se crea un data frame nuevo que contenga solo las variables Sex y BIB, a partir del data frame preparado en los pasos anteriores, y que además no contenga casos con NA en dichas variables:

```{r}
ANOVA_1 <- data.frame(data_ANOVA$Sex, data_ANOVA$BIB)
ANOVA_1 <- na.omit(ANOVA_1)
```

Se prueba normalidad para ambos sexos en la variable BIB:


```{r}
library(nortest)
by(data=ANOVA_1,INDICES = ANOVA_1$data_ANOVA.Sex,FUN=function(x){lillie.test(x$data_ANOVA.BIB)})

```
La prueba indica que hay normalidad en ambos grupos. Ahora se hace la prueba de igualdad de varianzas:

```{r}
fligner.test(ANOVA_1$data_ANOVA.BIB~ANOVA_1$data_ANOVA.Sex,ANOVA_1)
```
La prueba indica que hay igualdad de varianzas, por ello, se continua con la ANOVA

```{r}
anova<-aov(ANOVA_1$data_ANOVA.BIB~ANOVA_1$data_ANOVA.Sex,data=ANOVA_1)
summary(anova)
```
El resultado de la ANOVA parece confirmar que existen diferencias significativas en la anchura bi-ilíaca entre hombres y mujeres de esta colección.



# Apartado 8

Estos datos han permitido obtener una gran cantidad de resultados y llevar a cabo muchas pruebas de interés gracias a, principalmente, tres factores del data set. El primero es la abundancia en si del registro: la gran cantidad de casos distintos que recoge y la gran variedad de variables tomadas. Esto ha permitido seleccionar las variables mas indicadas para cada prueba que se ha realizado, teniendo siempre disponibles los suficientes individuos para llevarla a cabo. En segundo lugar, las variables que recoge son de distinto tipo, no teniendo únicamente variables continuas como cabe esperar de un data set osteológico, sino tambien de tipo factor (sexo, yacimiento) o numéricas discretas (edad). Esto permite realizar muchas pruebas de alto valor estadístico, como la ANOVA. Por último, dada la naturaleza de los datos que recoge, este data set tiene muchas variables "por parejas", es decir, que de cada medida ha recogido el valor tanto del lado derecho como del izquierdo. Esto permite realizar estudios de lateralidad, sustituir una variable por su homóloga hermana si no hubiese suficientes casos o se hubiese perdido información, o , si se supiese su lado preferencial (diestro o zurdo) hacer análisis de la influecia de esta variable sobre el desarrollo diferencial de cada lado del esqueleto. 

Hemos podido obtener algunas conclusiones intermediarias con el estudio del dataset que hemos hecho. No obstante ello, la cantidad de variables y observaciones presenta muchas mas oportunidades par un estudio mas produndizado que dependeria de la direccion que se quiere tomar (unos huesos especificos? de una origen, genero, tamano especificos? haciendo unos algoritmos predictivos (como en el caso del SVM), usar otro algoritmo (por ejemplo regresion logistica o KNN)? en vez de tener un dataset de train y uno de test, usar también un subset del train para validacion?)
